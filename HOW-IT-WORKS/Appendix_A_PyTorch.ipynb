{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2a1b0d07-834d-4433-b546-27eb1319a00c",
   "metadata": {},
   "source": [
    "## Install `torch`\n",
    "link: https://pytorch.org"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7486a9b0-2fbb-4c07-b670-15d885eea030",
   "metadata": {},
   "source": [
    "**As a side note:** <br>\n",
    "You may want to check out the following cloud platforms:\n",
    "* AWS\n",
    "* MS Azure\n",
    "* GCP\n",
    "* Lightning AI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f4322f11-4666-43c0-bfb1-5e78086f03be",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.6.0'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "torch.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "47d67699-8a4c-4851-a826-ba072fee6729",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec8252b1-cbba-4a9c-ba93-5f145393ed2b",
   "metadata": {},
   "source": [
    "It returns `False` in my mac as my GPU is not supported."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "926356cb-b687-44ed-a2cf-cc0d685ed9ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "# check if Apple Silicon Chip can accelerate PyTorch's computation\n",
    "print(torch.backends.mps.is_available())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32c51d4b-0447-42f5-86f6-4e99d75fca1b",
   "metadata": {},
   "source": [
    "## Three main components of the PyTorch library\n",
    "\n",
    "(1) Tensors <br>\n",
    "(2) Automatic differentiation <br>\n",
    "(3) Deep Learning layers / pre-built model / etc <br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45161b25-c13f-425c-bc5a-aff093fb3113",
   "metadata": {},
   "source": [
    "## Tensors vs Numpy ndarray\n",
    "\n",
    "Tensors with rank n is like n-dim numpy array. Tensors have more features and they are supported for GPU's computation. Tensor with rank 0 is just a scalar."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f3e4bf2b-c912-4cf4-9942-81f2d1814e87",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================================\n",
      "data: \n",
      " 1\n",
      "type of out: \n",
      " <class 'torch.Tensor'>\n",
      "out: \n",
      " tensor(1)\n",
      "==================================================\n",
      "data: \n",
      " [2, 3, 4]\n",
      "type of out: \n",
      " <class 'torch.Tensor'>\n",
      "out: \n",
      " tensor([2, 3, 4])\n",
      "==================================================\n",
      "data: \n",
      " [[ 3  5]\n",
      " [ 0 -1]]\n",
      "type of out: \n",
      " <class 'torch.Tensor'>\n",
      "out: \n",
      " tensor([[ 3,  5],\n",
      "        [ 0, -1]])\n"
     ]
    }
   ],
   "source": [
    "# let's create some tensors!\n",
    "lst_of_data = [\n",
    "    1,\n",
    "    [2, 3, 4],\n",
    "    np.array([[3, 5],[0, -1]]),\n",
    "]\n",
    "\n",
    "for data in lst_of_data:\n",
    "    print('=' * 50)\n",
    "    print('data: \\n', data)\n",
    "    out = torch.tensor(data)\n",
    "    print('type of out: \\n', type(out))\n",
    "    print('out: \\n', out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4f86a7dc-8169-4576-8e7b-ef450ddf52fd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 3,  5],\n",
       "        [ 0, -1]])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = np.array([[3, 5],[0, -1]])\n",
    "a = torch.tensor(a)\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2a852313-c664-4c17-ace5-9b36a585fdef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 2])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "bccc681f-e4ce-407a-b07a-1b686bfb0f6c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 3],\n",
       "        [ 5],\n",
       "        [ 0],\n",
       "        [-1]])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a.view(4, -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3a6058e7-998d-4138-bf58-574c7aa67328",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 2])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "14d57a62-ca0c-4118-9b48-9ceccf883c2d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 3,  5],\n",
       "        [ 0, -1]])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "3494b5b8-c71a-4350-bb6e-e9266ee34c7f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 3,  0],\n",
       "        [ 5, -1]])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a.T"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc6b436a-11f8-4afd-b1bc-f8bf4fb023a9",
   "metadata": {},
   "source": [
    "## Backward propagation in computation graph"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b30c041-807d-46f0-baac-5db71cd8499a",
   "metadata": {},
   "source": [
    "A computation graph is a graph that represents a computation. For instance, y = a * x + 3 can be shown like:\n",
    "\n",
    "```mermaid\n",
    "flowchart LR\n",
    "\n",
    "A[a] --> C[*]\n",
    "B[x] --> C\n",
    "C --> C2[v]\n",
    "C2 --> E[+]\n",
    "D[3] --> E\n",
    "E --> F[y]\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a28d81b7-f618-4f18-b53c-d7d34904d641",
   "metadata": {},
   "source": [
    "To find out the impact of change in input on output, we can take the derivative $\\frac{\\partial{y}}{\\partial{x}}$. According to graph, the variable `y` depends on `v`, and `v` depends on `x`. So, we can use the chain rule:\n",
    "\n",
    "$\\frac{\\partial{y}}{\\partial{x}} = \\frac{\\partial{y}}{\\partial{v}} \\times \\frac{\\partial{v}}{\\partial{x}}$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b874c73-7a7a-49df-b786-2b7153d91790",
   "metadata": {},
   "source": [
    "So, if an algorithm keeps updating those derivatives, I can quickly compute the new value, and plug them into the equation above to compute $\\frac{\\partial{y}}{\\partial{x}}$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "260239ad-50d5-4017-b722-6ad7fc8eb70e",
   "metadata": {},
   "source": [
    "**NOTE:** For more details, you may check out the Andrew NG's Deep Learning course in coursera."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2840a310-bba8-4728-969a-6c5535388f3f",
   "metadata": {},
   "source": [
    "`PyTorch` has a high-level method `.backward` which does all those good stuff for us! The author showed it for a simple logistic regression:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "7072b5f2-2e1e-4e9d-a0fd-f14df6f3692a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# logistic regression\n",
    "import torch.nn.functional as F\n",
    "\n",
    "y = torch.tensor([1.0])\n",
    "x1 = torch.tensor([1.1])\n",
    "w1 = torch.tensor([2.2], requires_grad=True)\n",
    "b = torch.tensor([0.0], requires_grad=True)\n",
    "z = x1 * w1 + b\n",
    "a = torch.sigmoid(z)\n",
    "loss = F.binary_cross_entropy(a, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "24749fd8-16eb-40b0-bd9e-9daaebbf3b53",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gradient of w1:  tensor([-0.0898])\n",
      "gradient of b:  tensor([-0.0817])\n"
     ]
    }
   ],
   "source": [
    "loss.backward()  # compute gradient of all leaf nodes that require_grad==True (?)\n",
    "\n",
    "print('gradient of w1: ', w1.grad)\n",
    "print('gradient of b: ', b.grad)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2c6df82-a14e-43ad-914d-99d751a31b5d",
   "metadata": {},
   "source": [
    "## Implementing multi-layer NN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "42ea1dc5-a8c4-40ce-98ed-fc8bfbef02de",
   "metadata": {},
   "outputs": [],
   "source": [
    "class NeuralNetwork(torch.nn.Module):\n",
    "    def __init__(self, n_inputs, n_outputs):\n",
    "        \"\"\"\n",
    "        Parameters\n",
    "        ----------\n",
    "        n_inputs : int\n",
    "            The number of nodes in the input layer\n",
    "\n",
    "        n_outputs : int\n",
    "            The number of nodes in the output layer\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        self.layers = torch.nn.Sequential(\n",
    "            # 1st hidden layer\n",
    "            torch.nn.Linear(n_inputs, 30),\n",
    "            torch.nn.ReLU(),\n",
    "            \n",
    "            # 2nd hidden layer\n",
    "            torch.nn.Linear(30, 20),\n",
    "            torch.nn.ReLU(),\n",
    "            \n",
    "            # output layer\n",
    "            torch.nn.Linear(20, n_outputs),\n",
    "        )\n",
    "\n",
    "\n",
    "    def forward(self, x):  \n",
    "        # what does this do?! \n",
    "        # Are we overwriting `forward` method?\n",
    "        logits = self.layers(x)\n",
    "        return logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "5945e437-57ef-4840-ba4e-3ffeec652332",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "NeuralNetwork(\n",
       "  (layers): Sequential(\n",
       "    (0): Linear(in_features=50, out_features=30, bias=True)\n",
       "    (1): ReLU()\n",
       "    (2): Linear(in_features=30, out_features=20, bias=True)\n",
       "    (3): ReLU()\n",
       "    (4): Linear(in_features=20, out_features=3, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_inputs = 50\n",
    "n_outputs = 3\n",
    "model = NeuralNetwork(n_inputs, n_outputs)\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "3e7560dd-b967-4d0b-9d16-d3fb2d861659",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================================\n",
      "Parameter containing:\n",
      "tensor([[-0.0568,  0.0116, -0.0765,  ...,  0.0267, -0.0036,  0.1051],\n",
      "        [-0.0800,  0.0317,  0.0497,  ..., -0.0003,  0.0717,  0.1366],\n",
      "        [-0.1140, -0.1359,  0.1081,  ..., -0.1306, -0.0522, -0.0165],\n",
      "        ...,\n",
      "        [-0.0078, -0.1096,  0.0351,  ..., -0.0469, -0.1103, -0.0339],\n",
      "        [ 0.1384, -0.0292,  0.0510,  ..., -0.0750, -0.1346, -0.1321],\n",
      "        [-0.0610, -0.0907, -0.0793,  ..., -0.0262,  0.1162, -0.0735]],\n",
      "       requires_grad=True)\n",
      "shape:  torch.Size([30, 50])\n",
      "1500\n",
      "==================================================\n",
      "Parameter containing:\n",
      "tensor([-0.0049, -0.0913, -0.0130, -0.0938, -0.0229,  0.0346, -0.0861,  0.0526,\n",
      "         0.1310, -0.0585,  0.1069, -0.0391,  0.0198, -0.0255, -0.1297, -0.0888,\n",
      "        -0.1074,  0.0288,  0.0842,  0.0734, -0.0732,  0.1014,  0.0902,  0.0656,\n",
      "        -0.1037,  0.1003,  0.0894,  0.0174,  0.1259, -0.0045],\n",
      "       requires_grad=True)\n",
      "shape:  torch.Size([30])\n",
      "30\n",
      "==================================================\n",
      "Parameter containing:\n",
      "tensor([[-0.0687,  0.1770, -0.0836,  0.0367,  0.1320,  0.0718,  0.0091, -0.0477,\n",
      "         -0.0711, -0.0468,  0.1624,  0.0442,  0.0778,  0.1637,  0.1410, -0.1090,\n",
      "          0.1173,  0.0296,  0.0265, -0.0554, -0.0369,  0.0653,  0.0738, -0.1655,\n",
      "          0.0455, -0.0046,  0.0030, -0.1617,  0.0369, -0.1770],\n",
      "        [ 0.0136,  0.0378,  0.1185,  0.0988, -0.1119,  0.0037,  0.1296,  0.0008,\n",
      "         -0.0811, -0.1275, -0.1683, -0.0488,  0.0812,  0.0116, -0.0427, -0.1463,\n",
      "          0.0398,  0.1550,  0.1801,  0.0022, -0.0626, -0.0484,  0.1388, -0.1450,\n",
      "          0.0270,  0.0062,  0.0458,  0.1062,  0.1725,  0.1276],\n",
      "        [-0.0988,  0.1404,  0.0050, -0.1522,  0.1309,  0.1747, -0.0537, -0.1446,\n",
      "          0.0807,  0.1393, -0.0504,  0.1061,  0.1559,  0.0912, -0.0752, -0.1190,\n",
      "          0.1719,  0.1232, -0.1340, -0.1072, -0.1231,  0.1314, -0.0066,  0.0342,\n",
      "          0.1688, -0.1117,  0.0817,  0.1326,  0.1442, -0.1445],\n",
      "        [ 0.1376, -0.0109,  0.1474, -0.0422, -0.1640, -0.0819, -0.0875,  0.0343,\n",
      "         -0.0612,  0.0152,  0.0210, -0.0397,  0.0774, -0.1586, -0.1095,  0.0051,\n",
      "         -0.0156,  0.0853, -0.0887, -0.0556,  0.0816,  0.1090,  0.0405,  0.0358,\n",
      "         -0.1197,  0.1791,  0.1046,  0.1107,  0.1169,  0.0802],\n",
      "        [-0.0346, -0.1076,  0.1532, -0.0839,  0.0732, -0.1128, -0.0436, -0.0735,\n",
      "          0.1150, -0.1014, -0.0744, -0.0799, -0.0439,  0.0764,  0.0575, -0.0273,\n",
      "         -0.1285,  0.0168, -0.0374,  0.0170,  0.0235,  0.0887, -0.1104,  0.0159,\n",
      "          0.0140,  0.0380,  0.0570,  0.0630, -0.0111,  0.1635],\n",
      "        [-0.0413,  0.0820,  0.0311,  0.1813,  0.0530,  0.1124, -0.0089, -0.0366,\n",
      "         -0.0732,  0.1732, -0.0952,  0.1214, -0.1771, -0.0460,  0.0805, -0.0256,\n",
      "          0.1644,  0.0790,  0.1042, -0.1260,  0.1109,  0.1196, -0.1429,  0.1584,\n",
      "         -0.0232,  0.1325,  0.1466,  0.0438, -0.0597, -0.1576],\n",
      "        [-0.1088, -0.1619,  0.0040,  0.0123,  0.1057, -0.0187, -0.0619,  0.0734,\n",
      "          0.0661,  0.0284, -0.0022,  0.0250, -0.1311,  0.1340, -0.0329, -0.0339,\n",
      "         -0.1063, -0.1441, -0.0463,  0.0914, -0.0284, -0.1415, -0.0193,  0.0026,\n",
      "          0.1624,  0.1222,  0.1596, -0.0657, -0.0466,  0.0195],\n",
      "        [ 0.1495, -0.1270,  0.1189,  0.1635,  0.1545, -0.0490, -0.1342,  0.0498,\n",
      "         -0.1632, -0.1388, -0.1120,  0.0701,  0.0721, -0.0256, -0.0559,  0.1322,\n",
      "          0.1139,  0.0517,  0.0980, -0.0434,  0.0511,  0.0036,  0.1622,  0.1292,\n",
      "         -0.1469,  0.0910,  0.0273,  0.0475,  0.1392, -0.1135],\n",
      "        [-0.0199, -0.0811, -0.1038,  0.0109, -0.0171, -0.1348, -0.0771, -0.0671,\n",
      "         -0.0429, -0.1479,  0.1667,  0.0935, -0.0498, -0.1080, -0.1409, -0.0813,\n",
      "         -0.0946,  0.1465,  0.0263, -0.1338, -0.0543, -0.0095, -0.1404, -0.0212,\n",
      "          0.1736, -0.1275, -0.0118, -0.1656,  0.0733,  0.1644],\n",
      "        [ 0.0387,  0.1733,  0.0772, -0.1470,  0.1403,  0.0108, -0.0327, -0.0103,\n",
      "          0.1076,  0.1648,  0.1560, -0.0059,  0.0692, -0.1756, -0.1177, -0.1790,\n",
      "          0.0488, -0.0191, -0.1390, -0.0400, -0.1271, -0.1001,  0.0889, -0.0213,\n",
      "          0.0917, -0.0664,  0.1080,  0.1407, -0.1216,  0.1602],\n",
      "        [-0.1698,  0.0313, -0.1357, -0.0974, -0.1349, -0.1622,  0.0222, -0.1822,\n",
      "          0.1802, -0.1443,  0.0640,  0.0958,  0.1581, -0.0308,  0.1305,  0.1654,\n",
      "         -0.0213, -0.0465,  0.1056, -0.0643, -0.1393,  0.0085,  0.1399,  0.1035,\n",
      "          0.1386, -0.0190,  0.1199, -0.0729, -0.0520,  0.1326],\n",
      "        [-0.1773, -0.0219, -0.0018,  0.0776, -0.0415, -0.0853,  0.1003, -0.0222,\n",
      "          0.0396,  0.1716,  0.0206,  0.1567, -0.1598,  0.0213,  0.1206,  0.1405,\n",
      "          0.1439, -0.1650, -0.0328,  0.1221,  0.0729, -0.0321,  0.1648,  0.0575,\n",
      "         -0.1417,  0.0823, -0.1814, -0.0388, -0.1237,  0.1807],\n",
      "        [-0.1483, -0.1079, -0.1491, -0.0188, -0.0262,  0.1028,  0.1160, -0.1230,\n",
      "          0.1713, -0.1661, -0.1361,  0.0093, -0.1099, -0.0267, -0.1077,  0.1819,\n",
      "          0.0208, -0.1579,  0.1169, -0.0572,  0.0531,  0.0855, -0.0756, -0.0370,\n",
      "         -0.1257, -0.1555, -0.0672,  0.0390,  0.0430,  0.1813],\n",
      "        [ 0.0109, -0.1026, -0.1507, -0.1324, -0.0353,  0.0087, -0.0082,  0.1481,\n",
      "          0.0812, -0.0866, -0.1506, -0.0367,  0.1788,  0.0962, -0.0496, -0.1724,\n",
      "         -0.1092, -0.1611, -0.0286,  0.0635, -0.0101,  0.1404,  0.0083,  0.0320,\n",
      "          0.0602,  0.1641,  0.0635,  0.0912,  0.0881, -0.0813],\n",
      "        [-0.0411,  0.1207, -0.1120,  0.0848, -0.1651, -0.1727, -0.1804, -0.0127,\n",
      "          0.1463,  0.1781, -0.0871, -0.0525, -0.1794,  0.1147, -0.1415,  0.1269,\n",
      "         -0.0408,  0.0425, -0.1646, -0.0422, -0.0059,  0.1776,  0.1331,  0.1622,\n",
      "          0.0174, -0.0298, -0.1772,  0.0845, -0.0394,  0.0617],\n",
      "        [ 0.1074, -0.1338,  0.0267, -0.1104,  0.0635,  0.1263,  0.0945, -0.1088,\n",
      "         -0.1361, -0.1715, -0.0838, -0.1259,  0.1359,  0.0603,  0.1070, -0.1661,\n",
      "         -0.0292, -0.1754, -0.1204,  0.0981,  0.0951,  0.1807, -0.0420,  0.1301,\n",
      "          0.0683,  0.0707, -0.0657,  0.1385, -0.0786,  0.0937],\n",
      "        [ 0.0639, -0.0414,  0.1242, -0.0527,  0.1600,  0.1767, -0.1303,  0.1441,\n",
      "          0.1622,  0.1219, -0.1402, -0.1372, -0.0526,  0.0669,  0.0611, -0.1473,\n",
      "          0.0728, -0.1026, -0.1013, -0.1655, -0.0474,  0.0145,  0.1084,  0.1145,\n",
      "          0.0682, -0.0473,  0.1743, -0.0228, -0.0274, -0.0115],\n",
      "        [ 0.1236,  0.0707,  0.0222, -0.1570, -0.0973, -0.1471,  0.0305,  0.1314,\n",
      "         -0.1458,  0.1092, -0.0067, -0.1496,  0.0360, -0.1772, -0.1408, -0.1369,\n",
      "          0.1426,  0.1496,  0.1229, -0.0754, -0.1342,  0.1215, -0.0505,  0.0429,\n",
      "         -0.1738, -0.1205,  0.1685,  0.0172, -0.0182, -0.0718],\n",
      "        [ 0.0908,  0.1325, -0.1718,  0.1661, -0.0089,  0.0602,  0.1734,  0.1029,\n",
      "          0.1423,  0.1791,  0.1675,  0.1553, -0.1337, -0.0137,  0.0077,  0.0434,\n",
      "         -0.0629, -0.1356, -0.0415,  0.1669, -0.0177,  0.1311,  0.1458, -0.1176,\n",
      "         -0.1752, -0.1399,  0.0148,  0.1327,  0.1542,  0.0910],\n",
      "        [ 0.0890, -0.1018,  0.0074,  0.1534, -0.1790, -0.0473,  0.1729, -0.0378,\n",
      "          0.0890,  0.1070, -0.1271,  0.0765,  0.0015,  0.1647,  0.0826, -0.0677,\n",
      "         -0.0444, -0.0625, -0.1267,  0.1798, -0.0594,  0.1620, -0.1232, -0.1765,\n",
      "          0.1274, -0.0128, -0.1261, -0.1608,  0.1315,  0.1245]],\n",
      "       requires_grad=True)\n",
      "shape:  torch.Size([20, 30])\n",
      "600\n",
      "==================================================\n",
      "Parameter containing:\n",
      "tensor([ 0.0139,  0.1755,  0.1307, -0.1126,  0.0281,  0.1521,  0.1620, -0.1014,\n",
      "         0.1555,  0.0092, -0.0333,  0.1680, -0.1103,  0.1569,  0.1690,  0.1433,\n",
      "        -0.1299,  0.0085, -0.0866,  0.1302], requires_grad=True)\n",
      "shape:  torch.Size([20])\n",
      "20\n",
      "==================================================\n",
      "Parameter containing:\n",
      "tensor([[ 0.0929,  0.0225, -0.1037, -0.0497,  0.0858, -0.1042,  0.1430, -0.0411,\n",
      "         -0.0522,  0.0393,  0.2074, -0.0968, -0.1958, -0.1200, -0.0007,  0.1195,\n",
      "         -0.1269,  0.0859, -0.0334, -0.0770],\n",
      "        [-0.1685, -0.1508, -0.0667,  0.1432, -0.2124,  0.0174, -0.1433,  0.1504,\n",
      "         -0.1203, -0.0633, -0.0276,  0.1994, -0.1387,  0.0710,  0.0922,  0.2038,\n",
      "          0.2178,  0.0376, -0.1655,  0.1271],\n",
      "        [-0.1088,  0.0600,  0.0458,  0.1806, -0.0931, -0.1181, -0.1879, -0.1724,\n",
      "         -0.1081, -0.0776,  0.1216, -0.2167, -0.0984, -0.0730, -0.1381,  0.1996,\n",
      "         -0.0916,  0.0874, -0.0877,  0.1016]], requires_grad=True)\n",
      "shape:  torch.Size([3, 20])\n",
      "60\n",
      "==================================================\n",
      "Parameter containing:\n",
      "tensor([-0.1751,  0.0823, -0.0705], requires_grad=True)\n",
      "shape:  torch.Size([3])\n",
      "3\n"
     ]
    }
   ],
   "source": [
    "for p in model.parameters():\n",
    "    print('=' * 50)\n",
    "    print(p)\n",
    "    print('shape: ', p.shape)\n",
    "    if p.requires_grad:\n",
    "        print(p.numel())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa6ca44f-65a6-4ab1-9748-1eff6e693ad0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
